[2025-06-05T18:36:23.762+0300] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-06-05T18:36:23.789+0300] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: push_autopark_import_pipeline.insert_test_data manual__2025-06-05T15:36:04.108922+00:00 [queued]>
[2025-06-05T18:36:23.802+0300] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: push_autopark_import_pipeline.insert_test_data manual__2025-06-05T15:36:04.108922+00:00 [queued]>
[2025-06-05T18:36:23.803+0300] {taskinstance.py:2866} INFO - Starting attempt 1 of 1
[2025-06-05T18:36:23.819+0300] {taskinstance.py:2889} INFO - Executing <Task(SQLExecuteQueryOperator): insert_test_data> on 2025-06-05 15:36:04.108922+00:00
[2025-06-05T18:36:23.823+0300] {standard_task_runner.py:72} INFO - Started process 29217 to run task
[2025-06-05T18:36:23.832+0300] {standard_task_runner.py:104} INFO - Running: ['airflow', 'tasks', 'run', 'push_autopark_import_pipeline', 'insert_test_data', 'manual__2025-06-05T15:36:04.108922+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/push_autopark_import_pipeline.py', '--cfg-path', '/var/folders/p0/qnxbkr491pd245gy9gbyyml40000gn/T/tmpziqlzet5']
[2025-06-05T18:36:23.835+0300] {standard_task_runner.py:105} INFO - Job 15: Subtask insert_test_data
[2025-06-05T18:36:23.923+0300] {task_command.py:467} INFO - Running <TaskInstance: push_autopark_import_pipeline.insert_test_data manual__2025-06-05T15:36:04.108922+00:00 [running]> on host MacBook-Pro-Margarita.local
[2025-06-05T18:36:24.067+0300] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='push_autopark_import_pipeline' AIRFLOW_CTX_TASK_ID='insert_test_data' AIRFLOW_CTX_EXECUTION_DATE='2025-06-05T15:36:04.108922+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-06-05T15:36:04.108922+00:00'
[2025-06-05T18:36:24.069+0300] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-06-05T18:36:24.070+0300] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-06-05T18:36:24.070+0300] {logging_mixin.py:190} INFO - Current task name:insert_test_data state:running start_date:2025-06-05 15:36:23.790208+00:00
[2025-06-05T18:36:24.071+0300] {logging_mixin.py:190} INFO - Dag name:push_autopark_import_pipeline and current dag run status:running
[2025-06-05T18:36:24.071+0300] {taskinstance.py:731} INFO - ::endgroup::
[2025-06-05T18:36:24.072+0300] {sql.py:278} INFO - Executing: TRUNCATE import_raw;

INSERT INTO import_raw (tecdocid, carid, ap2023, ap2024, type) VALUES
('1', NULL, 10, 9, 'PC'),
('2,3', '1', 100, 89, 'HCV'),
(NULL, '2', 1, 0, 'PC'),
(NULL, '3', 22, NULL, 'PC'),
('14', '1', 444, 345, 'HCV'),
('2', '2', 40, 11, 'HCV');
[2025-06-05T18:36:24.088+0300] {base.py:84} INFO - Retrieving connection 'postgres_car'
[2025-06-05T18:36:24.101+0300] {logging_mixin.py:190} WARNING - /Users/margaritaborodina/ALL_PROJECTS/airflow_car/venv/lib/python3.10/site-packages/airflow/providers/postgres/hooks/postgres.py:30 RemovedInAirflow3Warning: This module is deprecated. Please use `airflow.providers.common.sql.hooks.sql`.
[2025-06-05T18:36:24.112+0300] {base.py:84} INFO - Retrieving connection 'postgres_car'
[2025-06-05T18:36:24.113+0300] {sql.py:218} WARNING - This setter is for backward compatibility and should not be used.
Since the introduction of connection property, the providers listed below breaks due to assigning value to self.connection in their __init__ method.
* apache-airflow-providers-mysql<5.7.1
* apache-airflow-providers-elasticsearch<5.5.1
* apache-airflow-providers-postgres<5.13.0
[2025-06-05T18:36:24.121+0300] {sql.py:553} INFO - Running statement: TRUNCATE import_raw;

INSERT INTO import_raw (tecdocid, carid, ap2023, ap2024, type) VALUES
('1', NULL, 10, 9, 'PC'),
('2,3', '1', 100, 89, 'HCV'),
(NULL, '2', 1, 0, 'PC'),
(NULL, '3', 22, NULL, 'PC'),
('14', '1', 444, 345, 'HCV'),
('2', '2', 40, 11, 'HCV');, parameters: None
[2025-06-05T18:36:24.125+0300] {sql.py:562} INFO - Rows affected: 6
[2025-06-05T18:36:24.144+0300] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-06-05T18:36:24.146+0300] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=push_autopark_import_pipeline, task_id=insert_test_data, run_id=manual__2025-06-05T15:36:04.108922+00:00, execution_date=20250605T153604, start_date=20250605T153623, end_date=20250605T153624
[2025-06-05T18:36:24.160+0300] {logging_mixin.py:190} INFO - Task instance in success state
[2025-06-05T18:36:24.161+0300] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-06-05T18:36:24.162+0300] {logging_mixin.py:190} INFO - Dag name:push_autopark_import_pipeline queued_at:2025-06-05 15:36:04.133225+00:00
[2025-06-05T18:36:24.162+0300] {logging_mixin.py:190} INFO - Task hostname:MacBook-Pro-Margarita.local operator:SQLExecuteQueryOperator
[2025-06-05T18:36:24.185+0300] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-06-05T18:36:24.234+0300] {taskinstance.py:3895} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-06-05T18:36:24.235+0300] {local_task_job_runner.py:245} INFO - ::endgroup::
